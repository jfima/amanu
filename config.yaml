transcribe:
  provider: whisperx
  model: large-v3
refine:
  provider: ollama
  model: gpt-oss:20b
providers:
  ollama:
    retry_max: 3
    retry_delay_seconds: 5
    base_url: http://host.docker.internal:11434
    timeout: 600
    auto_pull_models: true
    use_gpu: true
    gpu_memory_limit: 24000
    preferred_quantization: q4_0
    transcription_model: whisper-large-v3
    refinement_model: gpt-oss:20b
  whisperx:
    language: Russian
  openrouter:
    site_url: https://github.com/yourusername/amanu
    app_name: amanu
debug: true
output_mode: standard
processing:
  language: auto
  compression_mode: compressed
  shelve_mode: timeline
  output:
    artifacts:
    - plugin: markdown
      template: default
      filename: default
    - plugin: pdf
      template: classic
      filename: classic
    - plugin: srt
      template: standard
      filename: standard
    - plugin: txt
      template: default
      filename: default
paths:
  input: /home/jfima/amanu/scribe-in
  work: /home/jfima/amanu/scribe-work
  results: /home/jfima/amanu/scribe-out
cleanup:
  failed_jobs_retention_days: 7
  completed_jobs_retention_days: 1
  auto_cleanup_enabled: true
